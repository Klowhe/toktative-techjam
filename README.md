# GeoReg Compliance Classifier

From Guesswork to Governance: Automating Geo-Regulation with LLM

TOKATIVE

Our team has developed a web application that allows employees to upload their Product Requirement Documents (PRDs) to automatically check for potential violations of geo-specific compliance requirements. To achieve this, we built a pipeline that leverages Retrieval-Augmented Generation (RAG) framework combined with a Large Language Model (LLM). The LLM has been further fine-tuned using Reinforcement Learning with Human Feedback (RLHF) to capture human-preferences in reasoning, and Reinforcement Learning with AI Feedback (RLAIF) to improve correctness in classification. The base model used is Meta Llama 3.1-8b and the fine-tuning was conducted using the sample dataset provided in the Information Document.

## Features

- **Document Upload & Analysis**: Upload PRDs and get AI-powered compliance analysis
- **Regulatory Intelligence**: Analysis based on actual regulatory documents (EU DSA, FL Bill, Utah Act, etc.)
- **Upload & Classify**: Submit PRD/TRD documents for AI-powered compliance analysis
- **Results Dashboard**: View compliance classifications
- **Feature Detail**: Deep dive into AI analysis results with full reasoning
- **No Mock Data**: 100% real AI analysis - no hardcoded or fallback data
- **Modern UI**: Clean, TikTok-styled interface focused on AI insights

## Tech Stack

### Frontend
- **Framework**: Lynx JS (React-style components), Vanilla JavaScript ES6+
- **Styling**: Custom CSS with TikTok brand colors (red #FF3361, cyan #25F4EE, teal #009995)
- **Build Tool**: Vite
- **Router**: Custom SPA router

### Backend
- **API**: Flask (Python)
- **AI Models**: Ollama (llama3.1:8b for chat, mxbai-embed-large for embeddings)
- **Vector Database**: Qdrant Cloud
- **Document Processing**: LangChain for text splitting and embedding
- **Environment**: .env configuration for secure credential management

### Regulatory Data Sources
- EU Digital Services Act (DSA)
- Florida Online Protection Bill
- Utah Social Media Regulation Act
- NCMEC Guidelines
- California POKSMAA

## Project Structure

```
/app                           # Frontend application
  /api
    realAdapter.js            # Real API adapter for backend integration
    api.js                    # API interface
  /pages
    Login.js                  # Authentication page
    Upload-simple.js          # Feature upload for classification
    Features.js               # Results dashboard (no hardcoded data)
    FeatureDetail.js          # Legacy component (not used)
  /components
    TopNav.ts                 # Navigation component
    FlagBadge.ts             # Compliance flag badges
    ConfidenceMeter.ts       # Confidence visualization
    [Other components...]
  /lib
    router.js                # SPA routing
    utils.js                 # Utility functions
  /styles
    globals.css              # Global styles
  main-simple.js             # Main application entry point

/src                          # Backend application
  /api
    ollama_api.py            # Ollama AI integration
    qdrant_api.py            # Qdrant vector database integration
  /config
    collections.py           # Regulatory document collections mapping
  app.py                     # Flask API server
  main.py                    # Core analysis logic
  
/data
  chunks_output.json         # Processed regulatory document chunks

.env                         # Environment variables (Qdrant credentials)
requirements.txt             # Python dependencies
package.json                 # Node.js dependencies
```

## RAG Framework and the Preparation of Data for Reinforcement Learning

To develop the RAG framework, the following legal documents have been preprocessed using LangChain and embedded using mxbai-embed-large. Then, the embeddings were uploaded onto our chosen vector database, Qdrant.

- EU Digital Services Act
- California Senate Bill 976 Protecting Our Kids from Social Media Addiction Act
- Florida House Bill 3: Online Protections for Minors
- Utah Social Media Regulation Act
- 18 U.S.C. 2258A (Reporting requirements of providers)

For each feature name and feature description, the most relevant chunks for the vector database were retrieved and fed into the raw Llama 3.1-8b model as context to generate the following output:
- A classification of yes, no, or maybe on whether
- Reasoning

Given that none of our team members are legally trained, the correctness of the classification generated by the Llama model was deferred to Gemini 2.0. On the other hand, our team members evaluated the reasoning capabilities of the Llama model and provided it a score. The classification and reasoning scores were then combined and used to finetune the model.

## Reinforcement Learning

Our method is a form of policy gradient reinforcement learning, inspired by the techniques used in Reinforcement Learning from Human Feedback (RLHF). In this model:

- The Agent is the meta-llama/Meta-Llama-3.1-8B model.
- The Action is the act of generating a textual analysis or "reasoning" based on a feature's description and a related regulation along with its classification.
- The Reward is a pre-calculated numerical score (scaled between 0 and 1) assigned to each piece of generated reasoning with its classification. A high reward (e.g., 1.0) signifies that the reasoning correctly and clearly flags the need for geo-specific logic, while a low reward (e.g., 0.1) indicates it was incorrect or irrelevant.

The model is fine-tuned using a reward-based reinforcement learning loop to improve its accuracy in flagging compliance risks.

The core of this process is a policy loss function, calculated as -log_probability * reward. By minimizing this loss, the training algorithm reinforces outputs that receive a high reward score. This effectively teaches the model to increase the probability of generating reasoning that is considered high-quality and correct, thereby improving its ability to identify compliance issues.

The entire reinforcement learning lifecycle is managed on Amazon Web Services (AWS) to ensure scalability and robustness. The fine-tuning of the 8-billion-parameter Llama model was conducted efficiently using Parameter-Efficient Fine-Tuning (PEFT) with Low-Rank Adaptation (LoRA), which significantly reduces computational costs by only training a small fraction of the model's parameters (~0.1%). Key hyperparameters, such as a learning rate of 1e-4 and three training epochs, were chosen to ensure stable and effective learning. The training process itself was orchestrated on Amazon SageMaker using a g4dn GPU instance.

The script automated the entire job: provisioning the instance, copying training data from S3, running the training code, and saving the resulting fine-tuned model artifacts back to S3 as a model.tar.gz file.

## Quick Start

### Prerequisites
- **Node.js** 16+ and npm
- **Python** 3.8+ and pip
- **Homebrew** (for macOS Ollama installation)

### 1. Clone and Setup
```bash
git clone <repository-url>
cd toktative-techjam
```

### 2. Install Dependencies

**Frontend:**
```bash
npm install
```

**Backend:**
```bash
pip3 install -r requirements.txt
```

### 3. Install and Setup Ollama (AI Models)

**Install Ollama:**
```bash
# macOS
brew install ollama

# Start Ollama service
brew services start ollama
```

**Download required models:**
```bash
# Embedding model for document similarity
ollama pull mxbai-embed-large

# Chat model for analysis generation
ollama pull llama3.1:8b
```

### 4. Start the Application

Start backend:
```bash
cd src
python3 app.py
```

Start frontend (new terminal):
```bash
npm run dev
```

### 5. Access the Application
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:5001

Start frontend (Terminal 2):
```bash
npm run dev
```

### 6. Access the Application
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:5001
- **Health Check**: http://localhost:5001/health

## Usage Guide

### Login & Navigation
1. **Login**: Enter any name and email (demo authentication)
2. **Upload**: Navigate to upload page to submit features for analysis
3. **Features**: View analysis results and detailed AI insights

### Feature Analysis Workflow
1. **Upload Feature**:
   - Enter feature title and description
   - Provide detailed PRD/TRD requirements text
   - Submit for AI analysis

2. **AI Processing**:
   - System queries Qdrant vector database for relevant regulations
   - Ollama AI models analyze compliance requirements
   - Returns structured analysis with confidence scores

3. **View Results**:
   - See AI classification (Yes/No/Maybe for compliance risk)
   - Review detailed reasoning and identified regulations
   - Check confidence scores and risk levels
   - Access full raw AI analysis

### Features Dashboard
- **Clean Interface**: No search bars or filters - focus on AI insights
- **Real Data Only**: Shows only actual analyzed features (no mock data)
- **Detailed Views**: Click features to see comprehensive AI analysis
- **Rich Information**: Confidence meters, risk levels, regulation detection

## ðŸ”§ Configuration

### Environment Variables
```env
QDRANT_API_KEY=<your-qdrant-api-key>
QDRANT_ENDPOINT=<your-qdrant-endpoint>
FLASK_ENV=production  # Optional: disable debug mode
```

### Available Regulatory Sources
- `eu_dsa.pdf` - EU Digital Services Act
- `fl_bill.pdf` - Florida Online Protection Bill  
- `utah_regulation_act.pdf` - Utah Social Media Regulation Act
- `ncmec.pdf` - NCMEC Guidelines
- `ca_poksmaa.pdf` - California POKSMAA

## ðŸ§  AI Analysis Pipeline

### 1. Document Retrieval
- Query embedding generated using mxbai-embed-large
- Qdrant vector search finds most relevant regulatory passages
- Typically retrieves 3-5 most relevant document chunks

### 2. AI Analysis
- llama3.1:8b model analyzes feature against retrieved regulations
- Generates structured compliance assessment
- Provides detailed reasoning and confidence scoring

### 3. Response Processing
- Extracts key information: flag, confidence, regulations, reasoning
- Classifies risk levels and age group targeting
- Returns structured JSON with full analysis details

## ðŸ“Š Analysis Output

Each AI analysis provides:
- **Compliance Flag**: Yes/No/Maybe for regulatory risk
- **Target Age Group**: All Ages/Under 18/Adults Only
- **Identified Regulations**: Specific laws/guidelines triggered
- **Detailed Reasoning**: Full AI explanation of analysis
- **Retrieved Documents**: Number of regulatory docs consulted
- **Raw Analysis**: Complete unprocessed AI response

## ðŸ›  Development

### Frontend Development
```bash
npm run dev          # Start Vite dev server
npm run build        # Build for production
npm run preview      # Preview production build
```

### Backend Development
```bash
cd src
python3 app.py       # Start Flask development server
```

### Testing API Endpoints
```bash
# Health check
curl http://localhost:5001/health

# Analyze feature
curl -X POST http://localhost:5001/api/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Feature Title",
    "description": "Feature description", 
    "prd_text": "Detailed requirements"
  }'
```

## Key Files

- **`app/main-simple.js`**: Frontend application entry point
- **`src/app.py`**: Flask API server with analysis endpoints
- **`src/main.py`**: Core AI analysis logic
- **`.env`**: Environment configuration (create this file)
- **`start.sh`**: Quick start script for both servers
- **`INTEGRATION.md`**: Detailed integration guide

## Troubleshooting

### Backend Issues
- **Connection refused**: Ensure backend is running on port 5001
- **Ollama errors**: Check if `brew services list | grep ollama` shows "started"
- **Model issues**: Re-run `ollama pull mxbai-embed-large` and `ollama pull llama3.1:8b`

### Frontend Issues  
- **Build errors**: Run `npm install` to ensure dependencies
- **API errors**: Check backend health at http://localhost:5001/health

### Environment Issues
- **Missing .env**: Create file with Qdrant credentials
- **Wrong directory**: Ensure backend runs from `src/` directory

## Architecture

### Frontend Architecture
- **Lynx JS**: Component-based architecture similar to React
- **Real API Integration**: Direct communication with Flask backend
- **No Mock Data**: 100% real AI analysis results
- **Responsive Design**: TikTok-styled modern interface

### Backend Architecture
- **Flask API**: RESTful endpoints for health and analysis
- **Ollama Integration**: Local AI models for embeddings and chat
- **Qdrant Vector DB**: Cloud-hosted regulatory document search
- **Document Processing**: LangChain for text chunking and embedding

### Data Flow
1. User submits feature via frontend form
2. Frontend sends POST request to `/api/analyze`
3. Backend generates embedding for user's feature description
4. Qdrant vector search retrieves relevant regulatory passages
5. Ollama chat model analyzes feature against regulations
6. Backend returns structured analysis to frontend
7. Frontend displays results with reasoning

## API Reference

### Endpoints

#### `GET /health`
Returns backend health status and configuration

#### `POST /api/analyze`
Analyzes feature for regulatory compliance

**Request Body:**
```json
{
  "title": "Feature Title",
  "description": "Feature description",
  "prd_text": "Detailed PRD/TRD text",
  "source_file": "eu_dsa.pdf"  // Optional
}
```

**Response:**
```json
{
  "success": true,
  "feature": {
    "id": "feat_abc123",
    "title": "Feature Title",
    "flag": "Yes|No|Maybe",
    "reasoning": "AI analysis explanation...",
    "regulations": ["EU Digital Services Act"],
    "age": "Under 18|All Ages"
  },
  "raw_analysis": "Full AI response...",
  "retrieved_documents": 3,
  "mode": "ai"
}
```

## Troubleshooting

## Project Status

### Completed Features
- Full-stack AI integration with Ollama + Qdrant
- Real regulatory document analysis
- Clean UI without hardcoded data
- Full analysis viewing capability
- Environment-based configuration
- Health monitoring and error handling

### Future Enhancements
- User authentication and session management
- Feature history and persistence
- Additional regulatory jurisdictions
- Batch analysis capabilities
- Advanced filtering and search
- PDF document upload and parsing
- Email notifications and sharing
- Audit trail and compliance reporting

---

Built for TikTok TechJam 2025

The app comes with 3 pre-loaded examples:

1. **Teen sleep mode (US)** â†’ Yes (youth protection regulations)
2. **Geofence US rollout for market testing** â†’ No (business decision)
3. **Filter available globally except KR** â†’ Maybe (unclear requirements)

## Mobile Support

- Responsive design for mobile devices
- Touch-friendly navigation
- Collapsible filters and sections
- Optimized table layouts

## Future Backend Integration

To connect a real backend:

1. Replace `createApi('mock')` with `createApi('http')` in components
2. Update `HttpAdapter` base URL to point to your API
3. No UI changes required - same interface contracts

## Browser Support

- Modern browsers with ES6+ support
- Chrome, Firefox, Safari, Edge
- Mobile Safari, Chrome Mobile

## License

MIT License